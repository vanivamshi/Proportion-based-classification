# Proportion-based-classification

Classification of dataset based on the proportion of features using a combination of quadrant-based classification and Euclidean distance. This method can be used to classify objects with dimentions. Hence, used Iris dataset as an example. Features of the program are,

1) Data Loading and Splitting - The Iris dataset is loaded using sklearn.datasets.load_iris(), which contains 150 samples of 3 types of flowers (Setosa, Versicolor, and Virginica) and 4 features (sepal length, sepal width, petal length, and petal width). The dataset is split into training and test sets using train_test_split() with a 70-30 split.
2)Proportion-Based Feature Representation - A custom function compute_proportions() calculates proportions for each feature relative to the total sum of all four features. This generates new feature vectors that capture the relative importance of each feature in a sample. These proportions are computed for the training set and used to define quadrants.
3) Quadrant-Based Classification - The training data is divided into quadrants using the np.percentile() function, which calculates the 25th, 50th, 75th, and 100th percentiles of the computed proportions. The program uses a custom classify_by_quadrants() function to check whether a test sample's proportions fall within certain ranges defined by the quadrants. If so, it assigns the sample to a placeholder class ("Q2 Class").
4) Euclidean Distance-Based Classification - If a test sample doesn't fit into any quadrant, the program falls back on a Euclidean distance method. This function calculates the Euclidean distance between the test sample's proportions and the training samples' proportions, and classifies the test sample based on the closest training sample's class.
5) Classification Workflow - In classify_test_data(), each test sample is first classified by quadrant. If it doesn't match any quadrant, it's classified using the Euclidean distance method. The model tries to leverage both quadrant-based rules (which represent predefined ranges) and distance-based nearest-neighbor classification to make predictions.
